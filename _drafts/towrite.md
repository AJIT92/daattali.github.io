http://rpubs.com/daattali/heatmapsGgplotVsLattice

all my extensions

google forms with shiny (use S3 or [mondodb](https://www.mongolab.com) or [mysql](http://www.freemysqlhosting.net/)  http://shiny.rstudio.com/articles/share-data.html 
mysql: con <- DBI::dbConnect(RMySQL::MySQL(), group = "deang", default.file=normalizePath("~/.my.cnf"))
not concerned about safety/input sanitization
doesnt seem like RMySQL supports preparesd statemetns so need to "hack" together sql statement creation with paste/sprintf
install sqlite: `sudo apt-get install sqlite3 libsqlite3-dev`, create database: `sqlite3 databasename.db`


analyze rbloggers twitter: what day of week is best to post? which posters get most attention? who posts the most? (if some blogs havent posted in over a year, maybe tell tal?) correlation betwwen posting freq and attention?
(lots of cutting corners: not considering any other social media, not looking at # of times post was shared directly from r-bloggers website, not looking at how much discussion the post generated by only at number of favorites and retweets)
```
library(twitteR)
library(httr)
library(XML)
library(plyr)
library(dplyr)

#setup_twitter_oauth(...)
userTimeline('Rbloggers')
MAX_TWEETS <- 3200
tweets_raw <- userTimeline('Rbloggers', n = MAX_TWEETS,
                           includeRts = FALSE, excludeReplies = TRUE) # 2013-09-02 to 2015-05-09

tweets <- 
  ldply(tweets_raw, function(x) {
    data_frame(id = x$id,
               date = as.Date(x$created),
               day = weekdays(date),
               favorites = x$favoriteCount,
               retweets = x$retweetCount,
               score = tweet_score(x),
               title = x$text,
               url = x$urls %>% .[['url']] %>% tail(1)
    )
  })

tweet_score <- function(tweet) {
  tweet$favoriteCount + tweet$retweetCount * 2
}

sum(tweets$favorites) / sum(tweets$retweets)  # 2.1

get_post_author_single <- function(url) {
  if (is.null(url)) {
    return(NA)
  }
  
  author_node <- 
    GET(url) %>%
    content("parsed") %>%
    getNodeSet("//a[@rel='author']")
  if (author_node %>% length != 1) {
    return(NA)
  }
  
  # {list(name = xmlValue(.), url = xmlGetAttr(., "href"))}
  author <- author_node %>% .[[1]] %>% xmlValue
  author  
}

get_post_author <- function(urls) {
  lapply(urls, get_post_author_single) %>% unlist
}


tweets %<>% mutate(author = get_post_author(url))

# write.csv(tweets, "tweets.csv", quote = TRUE, row.names = FALSE)

tweets_by_author <- ddply(tweets, ~ author, function(x) {
  data.frame(num = nrow(x),
             favorites = sum(x$favorites),
             retweets = sum(x$retweets),
             avg_score = mean(x$score)
  )}) %>%
  arrange(desc(num))
# I'm in the top 15 of avg score!

tweets_by_day <-
  ddply(tweets, ~ day, function(x) {
    data.frame(num = nrow(x),
               favorites_per_post = sum(x$favorites) / nrow(x),
               retweets_per_post = sum(x$retweets) / nrow(x),
               avg_score = mean(x$score)
    )})
# cool! looks like weekend (sat/sunday) get the least posts, BUT they both have the highest number of favorites and retweets!
```
