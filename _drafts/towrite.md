http://rpubs.com/daattali/heatmapsGgplotVsLattice

all my extensions

google forms with shiny (use S3 or [mondodb](https://www.mongolab.com) or [mysql](http://www.freemysqlhosting.net/)  http://shiny.rstudio.com/articles/share-data.html 
mysql: con <- DBI::dbConnect(RMySQL::MySQL(), group = "deang", default.file=normalizePath("~/.my.cnf"))
not concerned about safety/input sanitization
doesnt seem like RMySQL supports preparesd statemetns so need to "hack" together sql statement creation with paste/sprintf
install sqlite: `sudo apt-get install sqlite3 libsqlite3-dev`, create database: `sqlite3 databasename.db`


(lots of cutting corners: not considering any other social media, not looking at # of times post was shared directly from r-bloggers website, not looking at how much discussion the post generated by only at number of favorites and retweets)
didnt do statistical significance tests, didnt include fb data, didnt include # of shares via tweet button because it looks like most posts pre 2014 mostly have 0 so it'll introduce an unfair bias towards new posts

```
# write.csv(tweets, "tweets.csv", quote = TRUE, row.names = FALSE)



# preliminary look at data
ggplot(tweets) +
  geom_point(aes(favorites, retweets), size = 3, shape = 21, fill = "#888888") +
  theme_classic(30)


tweets_by_author <- ddply(tweets, ~ author, function(x) {
    data.frame(num = nrow(x),
               favorites = sum(x$favorites),
               retweets = sum(x$retweets),
               avg_score = mean(x$score) %>% round(digits = 1)
    )}) %>%
    arrange(desc(avg_score)) 
# I'm in the top 10 of avg score!
nrow(tweets_by_author)  # 420 unique authors since Sept 2013, so about 1/4 of the authors on r-bloggers haven't posted since I started grad school until today
ggplot(tweets_by_author) + geom_histogram(aes(num), binwidth = 1, fill = "#888888", color = "#444444") + theme_classic(30) + scale_x_continuous(limits = c(1, 50), breaks = c(1, seq(10, 50, 10))) + xlab("# of posts") + ylab("# of blogs who have\nexactly x posts") + ggtitle("How much does each blog\ncontribute?") + coord_flip()
# looks like a lot of people only posted once since... 

# who are the top contributors?
tweets_by_author %>% arrange(desc(num)) %>% .[1:10, , drop = FALSE]

# I expect to see a very strong correlation between # of times a tweet
# is favourited vs retweeted
cor(tweets_by_author$favorites, tweets_by_author$retweets)
# indeed, very strong correlation

# I wonder if users who post more also tend to post higher quality content?
cor(tweets_by_author$num, tweets_by_author$avg_score)
# looks like a pretty convincing 0 correlation there.

# Now let's see who the best scorers are, which blogs consistently
# contribute posts that get shared a lot
tweets_by_author %>% arrange(desc(avg_score)) %>% .[1:10, , drop = FALSE]
# First impression: **my name is there!** Woo! :D 
# Looks like a lot of one-hit wonders, which at first seems contradicting to the previous result because it looked like there is no relationship between # of posts and average post score. But this result **does** make sense because of two reasons: first of all, about 1/3 of the authors only have one article, so all other things equal, we expect 1/3 of the top posts to be by them. Secondly, it's much easier to put a lot of effort to produce one great and useful post rather than doing it over and over again.

# Let's see what all the posts looks like for the top scorers
top_authors <- tweets_by_author %>% arrange(desc(avg_score)) %>% .$author %>% .[1:10]
ggplot(tweets %>% filter(author %in% top_authors)) +
  geom_point(aes(favorites, retweets, fill = author), size = 5, shape = 21) +
  theme_classic(30) +
  scale_fill_brewer("Author", type = "qual", palette = 3)

# And let's see them again, in perspective to all tweets
ggplot(tweets) +
  geom_point(aes(favorites, retweets), size = 3, shape = 21, fill = "#888888") +
  theme_classic(30) +
  geom_point(data = tweets %>% filter(author %in% top_authors),
             aes(favorites, retweets, fill = author), size = 5, shape = 21) +
  scale_fill_brewer("Author", type = "qual", palette = 3)





tweets_by_day <-
  ddply(tweets, ~ day, function(x) {
    data.frame(num = nrow(x),
               favorites_per_post = sum(x$favorites) / nrow(x),
               retweets_per_post = sum(x$retweets) / nrow(x),
               avg_score = mean(x$score)
    )})
# cool! looks like weekend (sat/sunday) get the least posts, BUT they both have the highest number of favorites and retweets!

ggplot(tweets, aes(x = day, y = score, cex = 1.7), shape = 21) +
    geom_jitter(aes( fill = day), position = position_jitter(height = 0.4), show_guide=FALSE,shape=21, color = "#333333") + geom_line(data=tweets_by_day,aes(day,avg_score, group=1),color="#333333",size=1,)+ geom_point(data=tweets_by_day,aes(day, avg_score), shape =20,size=10,col="#333333") + theme_bw()


```
# wordcloud of most popular words in r-bloggers post titles
topwords <- 
    tweets$title %>%
    paste(collapse = " ") %>%
    stringr::str_split("\\s") %>%
    unlist %>%
    tolower %>%
    removePunctuation %>%
    removeWords(stopwords("english")) %>%
    wordStem %>%
    .[. != ""] %>% 
    .[. != "r"] %>%
    table %>%
    sort(decreasing = TRUE) %>%
    .[1:100]

wordcloud(names(topwords), topwords, min.freq = 10)
